{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabe486-5bb1-4902-8f60-7a750389e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch transformers langchain langchain-community langchain-huggingface faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "023d1cc1-3d8e-449d-8051-af60713f72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, pipeline\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6ad2dac-8539-4f6e-8591-e50a4a8d6ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: A Beginners Guide to the Stock Market.pdf\n",
      "Loading file: fastfacts-what-is-climate-change.pdf\n",
      "Loading file: report.pdf\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for root, _, files in os.walk(\"docs\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pdf\"):\n",
    "            print(f\"Loading file: {file}\")\n",
    "            loader = PyPDFLoader(os.path.join(root, file))\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "vectorstore = FAISS.from_documents(texts, HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16349ec6-6e05-4ecb-a9b4-6f3e3942ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"LaMini-T5-738M\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    checkpoint, \n",
    "    device_map='auto', \n",
    "    torch_dtype=torch.float32,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    'text2text-generation',\n",
    "    model=base_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm,\n",
    "                                          retriever,\n",
    "                                          return_source_documents=True)\n",
    "\n",
    "# TODO implement working chat history\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8adf9a9-3d5e-48ca-bc49-b91bbbd4ed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Understand Myself personality assessment and report is based on the Big Five Aspects Scale, the scientific model that describes your personality through the Big Five factors and each of their two aspects.\n"
     ]
    }
   ],
   "source": [
    "chat_history.clear()\n",
    "question = \"What is Understand Myself?\"\n",
    "generated_text = qa.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "answer = generated_text['answer']    \n",
    "# chat_history.append((question, answer))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fafff35f-d390-45d4-81b5-5145577e522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Understand Myself report is for Mihai Farcas.\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is the Understand Myself report for?\"\n",
    "generated_text = qa.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "answer = generated_text['answer']\n",
    "# chat_history.append((question, answer))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d517a076-d64c-4319-b9f4-e6790c4fee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Openness trait is a measure of creativity, artistic interest, and intelligence (particularly verbal intelligence) in the Big Five personality trait scientic model.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the Openness trait?\"\n",
    "generated_text = qa.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "answer = generated_text['answer']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8010217-5a9c-4935-b1da-a8c743e2e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score in Openness trait is 75.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is my score in Openness trait?\"\n",
    "generated_text = qa.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "answer = generated_text['answer']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5ef93f6-6936-4f86-9164-11fd985ed02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 75 percentile in Openness indicates where you stand on a particular trait with respect to the population.\n"
     ]
    }
   ],
   "source": [
    "question = \"What does 75 percentile mean in Openness?\"\n",
    "generated_text = qa.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "answer = generated_text['answer']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b805e-370d-4896-8671-77bc778c3f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privategpt",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
